{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652d82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import html\n",
    "import base64\n",
    "import pkgutil\n",
    "import ndjson\n",
    "\n",
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from IPython.display import display_html\n",
    "from json import dump, load, dumps\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from quadtreed3 import Quadtree, Node\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import norm\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def generate_contour_dict(xs: list[float], ys: list[float], labels: list[int]) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a grid dictionary object that encodes the contour plot of the\n",
    "    projected embedding space based on the labels.\n",
    "\n",
    "    Args:\n",
    "        xs ([float]): A list of x coordinates of projected points\n",
    "        ys ([float]): A list of y coordinates of projected points\n",
    "        labels ([int]): A list of category labels of projected points.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object encodes the contour plot.\n",
    "    \"\"\"\n",
    "    grid_density_json = {\"groupGrids\": {}, \"groupTotalPointSizes\": {}}\n",
    "\n",
    "    for label in set(labels):\n",
    "        label_indices = [i for i, l in enumerate(labels) if l == label]\n",
    "        label_xs = [xs[i] for i in label_indices]\n",
    "        label_ys = [ys[i] for i in label_indices]\n",
    "\n",
    "        # Here you would compute the contour for each label group.\n",
    "        # This can be a simpler process like determining bounding boxes\n",
    "        # or any other method that makes sense for your data.\n",
    "\n",
    "        # Example: just computing min/max coordinates for simplicity\n",
    "        x_min, x_max = min(label_xs), max(label_xs)\n",
    "        y_min, y_max = min(label_ys), max(label_ys)\n",
    "\n",
    "        # Store the results\n",
    "        grid_density_json[\"groupGrids\"][label] = [x_min, x_max, y_min, y_max]\n",
    "        grid_density_json[\"groupTotalPointSizes\"][label] = len(label_indices)\n",
    "\n",
    "    return grid_density_json\n",
    "\n",
    "\n",
    "\n",
    "def top_n_idx_sparse(matrix: csr_matrix, n: int) -> np.ndarray:\n",
    "    \"\"\"Return indices of top n values in each row of a sparse matrix\n",
    "    Retrieved from:\n",
    "        https://github.com/MaartenGr/BERTopic/blob/master/bertopic/_bertopic.py#L2801\n",
    "    Arguments:\n",
    "        matrix: The sparse matrix from which to get the top n indices per row\n",
    "        n: The number of highest values to extract from each row\n",
    "    Returns:\n",
    "        indices: The top n indices per row\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for le, ri in zip(matrix.indptr[:-1], matrix.indptr[1:]):\n",
    "        n_row_pick = min(n, ri - le)\n",
    "        values = matrix.indices[\n",
    "            le + np.argpartition(matrix.data[le:ri], -n_row_pick)[-n_row_pick:]\n",
    "        ]\n",
    "        values = [\n",
    "            values[index] if len(values) >= index + 1 else None for index in range(n)\n",
    "        ]\n",
    "        indices.append(values)\n",
    "    return np.array(indices)\n",
    "\n",
    "\n",
    "def top_n_values_sparse(matrix: csr_matrix, indices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return the top n values for each row in a sparse matrix\n",
    "    Arguments:\n",
    "        matrix: The sparse matrix from which to get the top n indices per row\n",
    "        indices: The top n indices per row\n",
    "    Returns:\n",
    "        top_values: The top n scores per row\n",
    "    \"\"\"\n",
    "    top_values = []\n",
    "    for row in range(indices.shape[0]):\n",
    "        scores = np.array(\n",
    "            [matrix[row, c] if c is not None else 0 for c in indices[row, :]]\n",
    "        )\n",
    "        top_values.append(scores)\n",
    "    return np.array(top_values)\n",
    "\n",
    "\n",
    "def merge_leaves_before_level(root: Node, target_level: int) -> Tuple[list, list, dict]:\n",
    "    \"\"\"\n",
    "    Merge all nodes to their parents until the tree is target_level tall (modify\n",
    "    root in-place) and extract all data from leaf nodes before or at the target_level.\n",
    "\n",
    "    Args:\n",
    "        root (Node): Root node\n",
    "        target_level (int): Target level\n",
    "\n",
    "    Returns:\n",
    "        csr_row_indexes (list): Row indexes for the sparse matrix. Each row is\n",
    "            a leaf node.\n",
    "        csr_column_indexes (list): Column indexes for the sparse matrix. Each column\n",
    "            is a prompt ID.\n",
    "        row_node_map (dict): A dictionary map row index to the leaf node.\n",
    "    \"\"\"\n",
    "\n",
    "    x0, y0, x1, y1 = root.position\n",
    "    step_size = (x1 - x0) / (2**target_level)\n",
    "\n",
    "    # Find all leaves at or before the target level\n",
    "    row_pos_map = {}\n",
    "    stack = [root]\n",
    "\n",
    "    # We create a sparse matrix by (data, (row index, column index))\n",
    "    csr_row_indexes, csr_column_indexes = [], []\n",
    "\n",
    "    # In the multiplication sparse matrix, each row represents a tile / collection,\n",
    "    # and each column represents a prompt ID\n",
    "    cur_r = 0\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        cur_node = stack.pop()\n",
    "\n",
    "        if cur_node.level >= target_level:\n",
    "            # A new traverse here to concatenate all the prompts from its subtree,\n",
    "            # and to merge it with its children\n",
    "            local_stack = [cur_node]\n",
    "            subtree_data = []\n",
    "\n",
    "            while len(local_stack) > 0:\n",
    "                local_node = local_stack.pop()\n",
    "\n",
    "                if len(local_node.children) == 0:\n",
    "                    # Leaf node\n",
    "                    subtree_data.extend(local_node.data)\n",
    "                else:\n",
    "                    for c in local_node.children[::-1]:\n",
    "                        if c is not None:\n",
    "                            local_stack.append(c)\n",
    "\n",
    "            # Detach all the children and get their data\n",
    "            cur_node.children = []\n",
    "            cur_node.data = subtree_data\n",
    "\n",
    "            # Register this node in a dictionary for faster access\n",
    "            row_pos_map[cur_r] = list(map(lambda x: round(x, 3), cur_node.position))\n",
    "\n",
    "            # Collect the prompt IDs\n",
    "            for d in cur_node.data:\n",
    "                csr_row_indexes.append(cur_r)\n",
    "                csr_column_indexes.append(d[\"pid\"])\n",
    "\n",
    "            # Move on to the next tile / collection\n",
    "            cur_r += 1\n",
    "\n",
    "        else:\n",
    "            if len(cur_node.children) == 0:\n",
    "                # Leaf node => it means this leaf is before the target level\n",
    "                # We need to adjust the node's position so that it has the same\n",
    "                # size as leaf nodes at the target_level\n",
    "                x, y = cur_node.data[0][\"x\"], cur_node.data[0][\"y\"]\n",
    "                xi, yi = int((x - x0) // step_size), int((y - y0) // step_size)\n",
    "\n",
    "                # Find the bounding box of current level of this leaf node\n",
    "                xi0, yi0 = x0 + xi * step_size, y0 + yi * step_size\n",
    "                xi1, yi1 = xi0 + step_size, yi0 + step_size\n",
    "                row_pos_map[cur_r] = list(\n",
    "                    map(lambda x: round(x, 3), [xi0, yi0, xi1, yi1])\n",
    "                )\n",
    "\n",
    "                # Collect the prompt IDs\n",
    "                for d in cur_node.data:\n",
    "                    csr_row_indexes.append(cur_r)\n",
    "                    csr_column_indexes.append(d[\"pid\"])\n",
    "\n",
    "                # Move on to the next tile / collection\n",
    "                cur_r += 1\n",
    "\n",
    "            else:\n",
    "                for c in cur_node.children[::-1]:\n",
    "                    if c is not None:\n",
    "                        stack.append((c))\n",
    "\n",
    "    return csr_row_indexes, csr_column_indexes, row_pos_map\n",
    "\n",
    "\n",
    "def get_tile_topics(count_mat, row_pos_map, ngrams, top_k=10):\n",
    "    \"\"\"Get the top-k important keywords from all rows in the count_mat.\n",
    "\n",
    "    Args:\n",
    "        count_mat (csr_mat): A count matrix\n",
    "        row_pos_map (dict): A dictionary that maps row index to the corresponding\n",
    "            leaf node's location in the quadtree\n",
    "        ngrams (list[str]): Feature names in the count_mat\n",
    "        top_k (int): Number of keywords to extract\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute tf-idf score\n",
    "    t_tf_idf_model = TfidfTransformer()\n",
    "    t_tf_idf = t_tf_idf_model.fit_transform(count_mat)\n",
    "\n",
    "    # Get words with top scores for each tile\n",
    "    indices = top_n_idx_sparse(t_tf_idf, top_k)\n",
    "    scores = top_n_values_sparse(t_tf_idf, indices)\n",
    "\n",
    "    sorted_indices = np.argsort(scores, 1)\n",
    "    indices = np.take_along_axis(indices, sorted_indices, axis=1)\n",
    "    scores = np.take_along_axis(scores, sorted_indices, axis=1)\n",
    "\n",
    "    # Store these keywords\n",
    "    tile_topics = []\n",
    "\n",
    "    for r in row_pos_map:\n",
    "        word_scores = [\n",
    "            (ngrams[word_index], round(score, 4))\n",
    "            if word_index is not None and score > 0\n",
    "            else (\"\", 0.00001)\n",
    "            for word_index, score in zip(indices[r][::-1], scores[r][::-1])\n",
    "        ]\n",
    "\n",
    "        tile_topics.append({\"w\": word_scores, \"p\": row_pos_map[r]})\n",
    "\n",
    "    return tile_topics\n",
    "\n",
    "\n",
    "def extract_level_topics(\n",
    "    root: Node,\n",
    "    count_mat: csr_matrix,\n",
    "    texts: list[str],\n",
    "    ngrams: list[str],\n",
    "    min_level=None,\n",
    "    max_level=None,\n",
    "):\n",
    "    \"\"\"Extract topics for all leaf nodes at all levels of the quadtree.\n",
    "\n",
    "    Args:\n",
    "        root (Noe): Quadtree node\n",
    "        count_mat (csr_matrix): Count vector for the corpus\n",
    "        texts (list[str]): A list of all the embeddings' texts\n",
    "        ngrams (list[str]): n-gram list for the count vectorizer\n",
    "    \"\"\"\n",
    "\n",
    "    level_tile_topics = {}\n",
    "\n",
    "    if min_level is None:\n",
    "        min_level = 0\n",
    "\n",
    "    if max_level is None:\n",
    "        max_level = root.height\n",
    "\n",
    "    for level in tqdm(list(range(max_level, min_level - 1, -1))):\n",
    "        # Create a sparse matrix\n",
    "        csr_row_indexes, csr_column_indexes, row_node_map = merge_leaves_before_level(\n",
    "            root, level\n",
    "        )\n",
    "\n",
    "        csr_data = [1 for _ in range(len(csr_row_indexes))]\n",
    "        tile_mat = csr_matrix(\n",
    "            (csr_data, (csr_row_indexes, csr_column_indexes)),\n",
    "            shape=(len(texts), len(texts)),\n",
    "        )\n",
    "\n",
    "        # Transform the count matrix\n",
    "        new_count_mat = tile_mat @ count_mat\n",
    "\n",
    "        # Compute t-tf-idf scores and extract keywords\n",
    "        tile_topics = get_tile_topics(new_count_mat, row_node_map, ngrams)\n",
    "\n",
    "        level_tile_topics[level] = tile_topics\n",
    "\n",
    "    return level_tile_topics\n",
    "\n",
    "\n",
    "def select_topic_levels(\n",
    "    max_zoom_scale,\n",
    "    svg_width,\n",
    "    svg_height,\n",
    "    x_domain,\n",
    "    y_domain,\n",
    "    tree_extent,\n",
    "    ideal_tile_width=35,\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatically determine the min and max topic levels needed for the visualization.\n",
    "\n",
    "    Args:\n",
    "        max_zoom_scale (float): Max zoom scale level\n",
    "        svg_width (int): SVG width\n",
    "        svg_height (int): SVG height\n",
    "        x_domain ([float, float]): [x min, x max]\n",
    "        y_domain ([float, float]): [y min, y max]\n",
    "        tree_extent ([[float, float], [float, float]]): The extent of the tree\n",
    "        ideal_tile_width (int, optional): Optimal tile width in pixel. Defaults to 35.\n",
    "    \"\"\"\n",
    "\n",
    "    svg_length = max(svg_width, svg_height)\n",
    "    world_length = max(x_domain[1] - x_domain[0], y_domain[1] - y_domain[0])\n",
    "    tree_to_world_scale = (tree_extent[1][0] - tree_extent[0][0]) / world_length\n",
    "\n",
    "    scale = 1\n",
    "    selected_levels = []\n",
    "\n",
    "    while scale <= max_zoom_scale:\n",
    "        best_level = 1\n",
    "        best_tile_width_diff = np.Infinity\n",
    "\n",
    "        for l in range(1, 21):\n",
    "            tile_num = 2**l\n",
    "            svg_scaled_length = scale * svg_length * tree_to_world_scale\n",
    "            tile_width = svg_scaled_length / tile_num\n",
    "\n",
    "            if abs(tile_width - ideal_tile_width) < best_tile_width_diff:\n",
    "                best_tile_width_diff = abs(tile_width - ideal_tile_width)\n",
    "                best_level = l\n",
    "\n",
    "        selected_levels.append(best_level)\n",
    "        scale += 0.5\n",
    "\n",
    "    return np.min(selected_levels), np.max(selected_levels)\n",
    "\n",
    "def generate_topic_dict(labels: list[int]) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a topic dictionary object based on labels.\n",
    "\n",
    "    Args:\n",
    "        labels ([int]): A list of category labels of projected points.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object encodes the topics.\n",
    "    \"\"\"\n",
    "    topic_dict = {\"data\": {}}\n",
    "    for label in set(labels):\n",
    "        topic_dict[\"data\"][label] = \"Topic \" + str(label)  # Assign a topic name\n",
    "\n",
    "    return topic_dict\n",
    "\n",
    "\n",
    "def generate_grid_dict(\n",
    "    xs: list[float],\n",
    "    ys: list[float],\n",
    "    texts: list[str],\n",
    "    embedding_name=\"My Embedding\",\n",
    "    grid_size=200,\n",
    "    max_sample=100000,\n",
    "    random_seed=202355,\n",
    "    max_zoom_scale=30,\n",
    "    svg_width=1000,\n",
    "    svg_height=1000,\n",
    "    ideal_tile_width=35,\n",
    "    labels: list[int] = None,\n",
    "    group_names: list[str] = None,\n",
    "    times: list[str] = None,\n",
    "    time_format: str = None,\n",
    "    image_label=None,\n",
    "    image_url_prefix=None,\n",
    "    opacity=None,\n",
    "):\n",
    "    \"\"\"Generate a grid dictionary object that encodes the contour plot and the\n",
    "    associated topics of different regions on the projected embedding space.\n",
    "\n",
    "    Args:\n",
    "        xs ([float]): A list of x coordinates of projected points\n",
    "        ys ([float]): A list of y coordinates of projected points\n",
    "        texts ([str]): A list of documents associated with points\n",
    "        embeddingName (str): Custom name of this embedding map\n",
    "        grid_size (int, optional): The resolution of the grid. Defaults to 200\n",
    "        max_sample (int, optional): Max number of samples to compute KDE from.\n",
    "            Defaults to 100000\n",
    "        random_seed (int, optional): Seed for the random state. Defaults to 202355\n",
    "        max_zoom_scale (float): The maximal zoom scale (default to zoom x 30)\n",
    "        svg_width (float): The approximate size of the wizmap window\n",
    "        svg_height (float): The approximate size of the wizmap window\n",
    "        ideal_tile_width (float): The ideal tile width in pixels\n",
    "        labels ([int]): A list of category labels of projected points. Labels\n",
    "            must be consecutive integers starting from 0. Defaults to None.\n",
    "        group_names ([str]): Category names associated with the given labels.\n",
    "            For example, the group name of label i is group_names[i]. Defaults\n",
    "            to None.\n",
    "        times ([str]): A list of times associated with data points. Defaults to None.\n",
    "        time_format (str): strptime format string to parse the time string in times\n",
    "        image_label (int): The label corresponds to an image point\n",
    "        image_url_prefix (str): The url prefix for all image texts\n",
    "        opacity (float): The opacity of data points. If it is None, WizMap will\n",
    "            dynamically adjust the opacity values. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary object encodes the grid data.\n",
    "    \"\"\"\n",
    "    print(\"Start generating contours...\")\n",
    "    contour_dict = generate_contour_dict(\n",
    "        xs,\n",
    "        ys,\n",
    "        grid_size=grid_size,\n",
    "        max_sample=max_sample,\n",
    "        random_seed=random_seed,\n",
    "        labels=labels,\n",
    "        group_names=group_names,\n",
    "        times=times,\n",
    "        time_format=time_format,\n",
    "    )\n",
    "\n",
    "    print(\"Start generating multi-level summaries...\")\n",
    "    topic_dict = generate_topic_dict(\n",
    "        xs,\n",
    "        ys,\n",
    "        texts,\n",
    "        max_zoom_scale=max_zoom_scale,\n",
    "        svg_width=svg_width,\n",
    "        svg_height=svg_height,\n",
    "        ideal_tile_width=ideal_tile_width,\n",
    "    )\n",
    "\n",
    "    # Add meta data to the final output\n",
    "    grid_dict = contour_dict\n",
    "    grid_dict[\"topic\"] = topic_dict\n",
    "    grid_dict[\"embeddingName\"] = embedding_name\n",
    "\n",
    "    if opacity is not None:\n",
    "        grid_dict[\"opacity\"] = opacity\n",
    "\n",
    "    # Create a config for image points\n",
    "    if image_label is not None:\n",
    "        image_config = {\"imageGroup\": image_label}\n",
    "\n",
    "        if image_url_prefix is not None:\n",
    "            image_config[\"imageURLPrefix\"] = image_url_prefix\n",
    "\n",
    "        grid_dict[\"image\"] = image_config\n",
    "\n",
    "    return grid_dict\n",
    "\n",
    "\n",
    "def generate_data_list(\n",
    "    xs: list[float],\n",
    "    ys: list[float],\n",
    "    texts: list[str],\n",
    "    times: list[str] = None,\n",
    "    labels: list[int] = None,\n",
    ") -> list[list]:\n",
    "    \"\"\"Generate a list of data points.\n",
    "\n",
    "    Args:\n",
    "        xs (list[float]): A list of x coordinates of projected points\n",
    "        ys (list[float]): A list of y coordinates of projected points\n",
    "        texts (list[str]): A list of documents associated with points\n",
    "        times (list[str], optional): A list of timestamps associated with points.\n",
    "            Defaults to [].\n",
    "        labels (list[int], optional): A list of category labels associated\n",
    "            with points. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        list[list]: A list of data points.\n",
    "    \"\"\"\n",
    "    print(\"Start generating data list...\")\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for i, x in enumerate(xs):\n",
    "        cur_row = [x, ys[i], texts[i]]\n",
    "\n",
    "        if times is not None:\n",
    "            cur_row.append(times[i])\n",
    "\n",
    "            if labels is not None:\n",
    "                cur_row.append(labels[i])\n",
    "\n",
    "        else:\n",
    "            if labels is not None:\n",
    "                cur_row.append(\"\")\n",
    "                cur_row.append(labels[i])\n",
    "\n",
    "        data_list.append(cur_row)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def save_json_files(\n",
    "    data_list: list,\n",
    "    grid_dict: dict,\n",
    "    output_dir=\"./\",\n",
    "    data_json_name=\"data.ndjson\",\n",
    "    grid_json_name=\"grid.json\",\n",
    "):\n",
    "    \"\"\"Save the dictionary and list as json files.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): The data list.\n",
    "        grid_dict (dict): The grid dictionary.\n",
    "        output_dir (str, optional): Folder to save the two json files.\n",
    "            Defaults to './'.\n",
    "        data_json_name (str, optional): Filename of the data json file.\n",
    "            Defaults to 'data.ndjson'.\n",
    "        grid_json_name (str, optional): Filename of the grid json file.\n",
    "            Defaults to 'grid.json'.\n",
    "    \"\"\"\n",
    "    with open(join(output_dir, data_json_name), \"w\", encoding=\"utf8\") as fp:\n",
    "        ndjson.dump(data_list, fp)\n",
    "\n",
    "    with open(join(output_dir, grid_json_name), \"w\", encoding=\"utf8\") as fp:\n",
    "        dump(grid_dict, fp)\n",
    "\n",
    "\n",
    "def _make_html(data_url, grid_url):\n",
    "    \"\"\"\n",
    "    Function to create an HTML string to bundle WizMap's html, css, and js.\n",
    "    We use base64 to encode the js so that we can use inline defer for <script>\n",
    "\n",
    "    We add another script to pass Python data as inline json, and dispatch an\n",
    "    event to transfer the data\n",
    "\n",
    "    Args:\n",
    "        data_url(str): URL to the data json file\n",
    "        grid_url(str): URL to the grid json file\n",
    "\n",
    "    Return:\n",
    "        HTML code with deferred JS code in base64 format\n",
    "    \"\"\"\n",
    "    # HTML template for WizMap widget\n",
    "    html_top = \"\"\"<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /><title>WizMap</title><style>html {font-size: 16px;-moz-osx-font-smoothing: grayscale;-webkit-font-smoothing: antialiased;text-rendering: optimizeLegibility;-webkit-text-size-adjust: 100%;-moz-text-size-adjust: 100%;scroll-behavior: smooth;}html, body {position: relative;width: 100%;height: 100%;overscroll-behavior: none;}body {margin: 0px;padding: 0px;box-sizing: border-box;font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;color: hsl(0, 0%, 29%);font-size: 1em;font-weight: 400;line-height: 1.5;}*, ::after, ::before {box-sizing: inherit;}a {color: rgb(0, 100, 200);text-decoration: none;}a:hover {text-decoration: underline;}a:visited {color: rgb(0, 80, 160);}label {display: block;}input, select, textarea {font-family: inherit;font-size: inherit;-webkit-padding: 0 0;padding: 0;margin: 0 0 0 0;box-sizing: border-box;border: 1px solid #ccc;border-radius: 2px;}input:disabled {color: #ccc;}button {all: unset;outline: none;cursor: pointer;}</style>\"\"\"\n",
    "    html_bottom = \"\"\"</head><body><div id=\"app\"></div></body></html>\"\"\"\n",
    "\n",
    "    # Read the bundled JS file\n",
    "    js_b = pkgutil.get_data(__name__, \"wizmap.js\")\n",
    "\n",
    "    # Read local JS file (for development only)\n",
    "    # with open(\"./wizmap.js\", \"r\") as fp:\n",
    "    #     js_string = fp.read()\n",
    "    # js_b = bytes(js_string, encoding=\"utf-8\")\n",
    "\n",
    "    # Encode the JS & CSS with base 64\n",
    "    js_base64 = base64.b64encode(js_b).decode(\"utf-8\")\n",
    "\n",
    "    # Pass data into JS by using another script to dispatch an event\n",
    "    messenger_js = f\"\"\"\n",
    "        (function() {{\n",
    "            const event = new Event('wizmapData');\n",
    "            event.dataURL = '{data_url}';\n",
    "            event.gridURL = '{grid_url}';\n",
    "            document.dispatchEvent(event);\n",
    "        }}())\n",
    "    \"\"\"\n",
    "    messenger_js = messenger_js.encode()\n",
    "    messenger_js_base64 = base64.b64encode(messenger_js).decode(\"utf-8\")\n",
    "\n",
    "    # Inject the JS to the html template\n",
    "    html_str = (\n",
    "        html_top\n",
    "        + \"\"\"<script defer src='data:text/javascript;base64,{}'></script>\"\"\".format(\n",
    "            js_base64\n",
    "        )\n",
    "        + \"\"\"<script defer src='data:text/javascript;base64,{}'></script>\"\"\".format(\n",
    "            messenger_js_base64\n",
    "        )\n",
    "        + html_bottom\n",
    "    )\n",
    "\n",
    "    return html.escape(html_str)\n",
    "\n",
    "\n",
    "def visualize(data_url, grid_url, height=700):\n",
    "    \"\"\"\n",
    "    Render WizMap in the output cell.\n",
    "\n",
    "    Args:\n",
    "        data_url(str): URL to the data json file\n",
    "        grid_url(str): URL to the grid json file\n",
    "        width(int): Width of the main visualization window\n",
    "        height(int): Height of the whole window\n",
    "\n",
    "    Return:\n",
    "        HTML code with deferred JS code in base64 format\n",
    "    \"\"\"\n",
    "    html_str = _make_html(data_url, grid_url)\n",
    "\n",
    "    # Randomly generate an ID for the iframe to avoid collision\n",
    "    iframe_id = \"wizmap-iframe-\" + str(int(random.random() * 1e8))\n",
    "\n",
    "    iframe = f\"\"\"\n",
    "        <iframe\n",
    "            srcdoc=\"{html_str}\"\n",
    "            frameBorder=\"0\"\n",
    "            width=\"100%\"\n",
    "            height=\"{height}px\"\n",
    "            id=\"{iframe_id}\"\n",
    "            style=\"border: 1px solid hsl(0, 0%, 90%); border-radius: 5px;\">\n",
    "        </iframe>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the iframe\n",
    "    display_html(iframe, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed2f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
